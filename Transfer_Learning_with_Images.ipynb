{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning with Images.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN827opLZBHis21HxCuQZyU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, you will learn how to classify images of cats and dogs by using transfer learning from a pre-trained network.\n",
        "\n",
        "A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task. You either use the pretrained model as is or use transfer learning to customize this model to a given task.\n",
        "\n",
        "The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\n",
        "\n",
        "In this notebook, you will try two ways to customize a pretrained model:\n",
        "\n",
        "1. `Feature Extraction`: Use the representations learned by a previous network to extract meaningful features from new samples. You simply add a new classifier, which will be trained from scratch, on top of the pretrained model so that you can repurpose the feature maps learned previously for the dataset.\n",
        "\n",
        "You do not need to (re)train the entire model. The base convolutional network already contains features that are generically useful for classifying pictures. However, the final, classification part of the pretrained model is specific to the original classification task, and subsequently specific to the set of classes on which the model was trained.\n",
        "\n",
        "2. `Fine-Tuning`: Unfreeze a few of the top layers of a frozen model base and jointly train both the newly-added classifier layers and the last layers of the base model. This allows us to \"fine-tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task.\n",
        "\n",
        "You will follow the general machine learning workflow.\n",
        "\n",
        "1. Examine and understand the data\n",
        "2. Build an input pipeline, in this case using Keras ImageDataGenerator\n",
        "3. Compose the model\n",
        "  * Load in the pretrained base model (and pretrained weights)\n",
        "  * Stack the classification layers on top\n",
        "4. Train the model\n",
        "5. Evaluate model"
      ],
      "metadata": {
        "id": "eYcGEmxCSd12"
      }
    }
  ]
}